{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize Faker for generating synthetic data\n",
        "faker = Faker()\n",
        "# Load spaCy model for entity recognition\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_hQUzBhkJyw",
        "outputId": "8edbbae5-d8d4-4c3d-c822-3377cd4b934a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Enron dataset from a CSV file\n",
        "# Ensure the file path is correct before running the script\n",
        "enron_emails = pd.read_csv(r\"emails.csv\")  # Update with the correct file path\n",
        "print(enron_emails.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko_f7YbPkNaZ",
        "outputId": "f056ad51-1e91-41f8-f0d6-d7a4df0b4398"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       file                                            message\n",
            "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
            "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
            "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
            "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
            "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse email fields\n",
        "def parse_email(message):\n",
        "    \"\"\"\n",
        "    Parse an email message to extract structured fields.\n",
        "    \"\"\"\n",
        "    fields = {}\n",
        "    # Extract common fields using regex\n",
        "    fields[\"Message-ID\"] = re.search(r\"Message-ID: (.+)\", message).group(1).strip() if re.search(r\"Message-ID: (.+)\", message) else None\n",
        "    fields[\"From\"] = re.search(r\"From: (.+)\", message).group(1).strip() if re.search(r\"From: (.+)\", message) else None\n",
        "    fields[\"To\"] = re.search(r\"To: (.+)\", message).group(1).strip() if re.search(r\"To: (.+)\", message) else None\n",
        "    fields[\"Subject\"] = re.search(r\"Subject: (.+)\", message).group(1).strip() if re.search(r\"Subject: (.+)\", message) else None\n",
        "    fields[\"Date\"] = re.search(r\"Date: (.+)\", message).group(1).strip() if re.search(r\"Date: (.+)\", message) else None\n",
        "\n",
        "    # Extract body by removing headers\n",
        "    body = re.split(r\"\\n\\n\", message, maxsplit=1)\n",
        "    fields[\"Body\"] = body[1].strip() if len(body) > 1 else \"\"\n",
        "\n",
        "    return fields\n",
        "\n",
        "# Apply the parsing function to extract email fields\n",
        "parsed_emails = enron_emails[\"message\"].apply(parse_email)\n",
        "parsed_emails_df = pd.DataFrame(parsed_emails.tolist())\n",
        "print(parsed_emails_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTJVtGDsl__F",
        "outputId": "d93c3fa4-845e-4aa9-8362-bda5d69e9213"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Message-ID                     From  \\\n",
            "0  <18782981.1075855378110.JavaMail.evans@thyme>  phillip.allen@enron.com   \n",
            "1  <15464986.1075855378456.JavaMail.evans@thyme>  phillip.allen@enron.com   \n",
            "2  <24216240.1075855687451.JavaMail.evans@thyme>  phillip.allen@enron.com   \n",
            "3  <13505866.1075863688222.JavaMail.evans@thyme>  phillip.allen@enron.com   \n",
            "4  <30922949.1075863688243.JavaMail.evans@thyme>  phillip.allen@enron.com   \n",
            "\n",
            "                        To    Subject                                   Date  \\\n",
            "0     tim.belden@enron.com       None  Mon, 14 May 2001 16:39:00 -0700 (PDT)   \n",
            "1  john.lavorato@enron.com        Re:   Fri, 4 May 2001 13:51:00 -0700 (PDT)   \n",
            "2   leah.arsdall@enron.com   Re: test  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)   \n",
            "3    randall.gay@enron.com       None  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)   \n",
            "4     greg.piper@enron.com  Re: Hello  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)   \n",
            "\n",
            "                                                Body  \n",
            "0                               Here is our forecast  \n",
            "1  Traveling to have a business meeting takes the...  \n",
            "2                     test successful.  way to go!!!  \n",
            "3  Randy,\\n\\n Can you send me a schedule of the s...  \n",
            "4                  Let's shoot for Tuesday at 11:45.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to replace PII using spaCy and Faker\n",
        "def replace_pii(text):\n",
        "    \"\"\"\n",
        "    Replace sensitive information in the text using spaCy and Faker.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    count = 1\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"EMAIL\", \"DATE\"]:\n",
        "            replacement = (\n",
        "                faker.name() if ent.label_ == \"PERSON\" else\n",
        "                faker.company() if ent.label_ == \"ORG\" else\n",
        "                faker.city() if ent.label_ == \"GPE\" else\n",
        "                faker.email() if ent.label_ == \"EMAIL\" else\n",
        "                faker.date()\n",
        "            )\n",
        "            text = text.replace(ent.text, replacement)\n",
        "    count = count + 1\n",
        "    return text\n",
        "\n",
        "# Fill missing values and apply de-identification to the dataset\n",
        "parsed_emails_df[\"Body\"] = parsed_emails_df[\"Body\"].fillna(\"\")\n",
        "parsed_emails_df[\"Subject\"] = parsed_emails_df[\"Subject\"].fillna(\"\")\n",
        "\n",
        "# Apply de-identification to body and subject\n",
        "parsed_emails_df[\"De-Identified_Body\"] = parsed_emails_df[\"Body\"].apply(replace_pii)\n",
        "parsed_emails_df[\"De-Identified_Subject\"] = parsed_emails_df[\"Subject\"].apply(replace_pii)"
      ],
      "metadata": {
        "id": "bYg82hLzmGMe"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI API via LangChain\n",
        "# Initialize OpenAI API via LangChain\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "llm = ChatOpenAI(temperature=0.2, model=\"gpt-4\", openai_api_key=openai_api_key)\n",
        "\n",
        "# Define prompt template for subject transformation\n",
        "subject_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"email_subject\"],\n",
        "    template=\"\"\"\n",
        "    Rewrite the subject line of the following email, ensuring it feels authentic, professional,\n",
        "    and suitable for a different context. Maintain the overall intent and tone of the subject\n",
        "    while introducing a subtle but realistic transformation.\n",
        "\n",
        "    Original Subject:\n",
        "    {email_subject}\n",
        "\n",
        "    Provide the rewritten subject line.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Define prompt template for body transformation\n",
        "body_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"email_body\"],\n",
        "    template=\"\"\"\n",
        "    Transform the body of the following email into a version that feels realistic, professional,\n",
        "    and contextually suitable for a different organization and domain.\n",
        "\n",
        "    Preserve the logical flow, professional tone, and structure of the email, ensuring it remains\n",
        "    natural and authentic. Replace any identifiable details such as names, organizations, locations,\n",
        "    and numbers with contextually appropriate alternatives. Subtly adapt industry-specific terms to\n",
        "    align with the new context while maintaining the overall meaning and intent of the original message.\n",
        "\n",
        "    Original Body:\n",
        "    {email_body}\n",
        "\n",
        "    Provide the transformed email body.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Create LangChains for Subject and Body\n",
        "subject_transformation_chain = LLMChain(llm=llm, prompt=subject_prompt_template)\n",
        "body_transformation_chain = LLMChain(llm=llm, prompt=body_prompt_template)\n",
        "\n",
        "# Generate synthetic subject and body\n",
        "parsed_emails_df[\"Synthetic_Subject\"] = parsed_emails_df[\"De-Identified_Subject\"].apply(\n",
        "    lambda subject: subject_transformation_chain.run({\"email_subject\": subject}) if subject else \"\"\n",
        ")\n",
        "\n",
        "parsed_emails_df[\"Synthetic_Body\"] = parsed_emails_df[\"De-Identified_Body\"].apply(\n",
        "    lambda body: body_transformation_chain.run({\"email_body\": body}) if body else \"\"\n",
        ")\n",
        "\n",
        "# Save results\n",
        "parsed_emails_df.to_csv(\"synthetic_emails_with_subject_and_body.csv\", index=False)\n",
        "print(\"Synthetic emails with separate columns for subject and body saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJFMa1oqFVcS",
        "outputId": "c2071398-c931-4180-c7f5-942fcf8eae7a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic emails with separate columns for subject and body saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load embedding model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def calculate_similarity(original, synthetic):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between original and synthetic text.\n",
        "    \"\"\"\n",
        "    original_embedding = model.encode(original)\n",
        "    synthetic_embedding = model.encode(synthetic)\n",
        "    return util.cos_sim(original_embedding, synthetic_embedding).item()\n",
        "\n",
        "# Calculate similarity scores\n",
        "parsed_emails_df[\"Similarity_Score\"] = parsed_emails_df.apply(\n",
        "    lambda row: calculate_similarity(row[\"Body\"], row[\"Synthetic_Body\"]), axis=1\n",
        ")\n",
        "\n",
        "# Save results\n",
        "parsed_emails_df.to_csv(\"synthetic_emails.csv\", index=False)\n",
        "print(\"Synthetic emails saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btYjjWMnqSF5",
        "outputId": "58909190-0d3b-48bb-f045-821e8fcf9636"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic emails saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(parsed_emails_df[\"Similarity_Score\"].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbOVMN2NGmxy",
        "outputId": "5fee697c-c07d-47e5-9b85-eabf88274fca"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    100.000000\n",
            "mean       0.517384\n",
            "std        0.155810\n",
            "min        0.168305\n",
            "25%        0.400129\n",
            "50%        0.527207\n",
            "75%        0.615530\n",
            "max        0.869910\n",
            "Name: Similarity_Score, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}